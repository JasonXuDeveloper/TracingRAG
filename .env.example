# TracingRAG Configuration

# Application
APP_NAME=TracingRAG
APP_VERSION=0.1.0
ENVIRONMENT=development
LOG_LEVEL=INFO
DEBUG=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# LLM Provider (OpenRouter)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# Main query model - Claude 3 Haiku is good balance of quality and cost
# Haiku: $0.25/1M input ($12x cheaper than Sonnet 3.5)
# Alternatives: claude-3.5-sonnet ($3/1M, better quality), gpt-4o-mini ($0.15/1M)
DEFAULT_LLM_MODEL=anthropic/claude-3-haiku
FALLBACK_LLM_MODEL=anthropic/claude-3-haiku
# Internal models for analysis, planning, and management
# Agent tasks REQUIRE JSON schema support
# Recommended: anthropic/claude-3-haiku ($0.25/1M, reliable, JSON schema)
# Alternatives:
#   - openai/gpt-4o-mini ($0.15/1M, cheaper)
#   - mistralai/mistral-small-3.2-24b-instruct:free (FREE but rate-limited)
# Note: Google Gemini models have JSON schema compatibility issues on OpenRouter
ANALYSIS_MODEL=anthropic/claude-3-haiku
EVALUATION_MODEL=anthropic/claude-3-haiku
QUERY_ANALYZER_MODEL=anthropic/claude-3-haiku
PLANNER_MODEL=anthropic/claude-3-haiku
MANAGER_MODEL=anthropic/claude-3-haiku
# Auto-linking model - used for analyzing relationships between memories
# Recommended: anthropic/claude-3-haiku (cost-efficient for batch analysis)
AUTO_LINK_MODEL=anthropic/claude-3-haiku

# Embedding Configuration
# Local model (default) - runs on your machine, no API costs
# Recommended models:
#  - sentence-transformers/all-mpnet-base-v2 (768 dim, English, good quality)
#  - sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (768 dim, 50+ languages)
#  - sentence-transformers/all-MiniLM-L6-v2 (384 dim, English, faster)
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
EMBEDDING_DIMENSION=768

# Qdrant (Vector Database)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=tracingrag_memories
QDRANT_GRPC_PORT=6334
QDRANT_USE_GRPC=false

# Neo4j (Graph Database)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=tracingrag123
NEO4J_DATABASE=neo4j
NEO4J_MAX_CONNECTION_POOL_SIZE=50

# PostgreSQL (Document Store)
DATABASE_URL=postgresql+asyncpg://tracingrag:tracingrag123@localhost:5432/tracingrag
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10
DATABASE_ECHO=false

# Redis (Caching)
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=10
CACHE_TTL=3600
CACHE_ENABLED=true

# Retrieval Configuration
DEFAULT_RETRIEVAL_LIMIT=10
MAX_RETRIEVAL_LIMIT=100
DEFAULT_GRAPH_DEPTH=2
MAX_GRAPH_DEPTH=5
ENABLE_HYBRID_SEARCH=true

# Memory Promotion
PROMOTION_CONFIDENCE_THRESHOLD=0.7
AUTO_PROMOTION_ENABLED=false
MAX_TRACE_HISTORY_CONTEXT=10

# Agent Configuration
AGENT_MAX_ITERATIONS=10
AGENT_TIMEOUT_SECONDS=900
ENABLE_AGENT_MEMORY=true
AGENT_THINKING_BUDGET=1000

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9100
ENABLE_TRACING=false
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=100

# Security
SECRET_KEY=your-secret-key-here-change-in-production
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
ALLOWED_HOSTS=*

# OpenAI (Optional - for automatic fallback if local model fails or better multilingual support)
# If OPENAI_API_KEY is set, will use OpenAI embeddings instead of local model
# OpenAI embeddings support 100+ languages with high quality
# Models: text-embedding-3-small (1536 dim), text-embedding-3-large (3072 dim)
OPENAI_API_KEY=
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
